{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df307b4-54c4-4c0e-a846-cbbe2499ca3d",
   "metadata": {},
   "source": [
    "# Comparing two classification models using `stambo`\n",
    "\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/Oulu-IMEDS/stambo/main?labpath=notebooks%2FClassification.ipynb)\n",
    "\n",
    "V1.1.3: © Aleksei Tiulpin, PhD, 2025\n",
    "\n",
    "This notebook shows an end-to-end example on how one can take a dataset, train two machine learning models, and conduct a statistical test to assess whether the two models are different. We will first use a set of classical metrics (basically the metrics from sklearn). At the end of the tutorial, we will show how one can generate a LaTeX report, and implement a custom metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebf8b7-3cea-4739-8f4d-0546b72329f5",
   "metadata": {},
   "source": [
    "## Import of necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091baaa3-7f21-46fa-9e2a-0277fc53a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stambo\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "SEED = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e256c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stambo.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e066e9d-6f01-4a57-b555-cf24b1022c80",
   "metadata": {},
   "source": [
    "## Loading the UCI breast cancer dataset and creating train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba8578f0-0b80-4c21-ab63-c0d4ca81050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.5, random_state=SEED, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xtr)\n",
    "\n",
    "Xtr = scaler.transform(Xtr)\n",
    "Xte = scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2cb8d9-343f-42d1-89b9-8fafe0d2c772",
   "metadata": {},
   "source": [
    "## Training the models\n",
    "\n",
    "We train a kNN and a logistic regression. Here, we can see that the logistic regression outperformes the kNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2bad13-2678-4df4-bb24-59e0ed90de54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN AUC: 0.9722 / LR AUC: 0.9918\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(Xtr, ytr)\n",
    "preds_knn = model.predict_proba(Xte)[:, 1]\n",
    "\n",
    "model = LogisticRegression(C=1e-2, random_state=42)\n",
    "model.fit(Xtr, ytr)\n",
    "preds_lr = model.predict_proba(Xte)[:, 1]\n",
    "\n",
    "\n",
    "auc_knn, auc_lr = roc_auc_score(yte, preds_knn), roc_auc_score(yte, preds_lr)\n",
    "print(f\"kNN AUC: {auc_knn:.4f} / LR AUC: {auc_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68886aa2-6944-4af3-afe9-e2a9d070d41f",
   "metadata": {},
   "source": [
    "## Statistical testing\n",
    "\n",
    "As stated in the documentation, the testing routine returns the `dict` of `tuple`. The keys in the dict are the metric tags, and the values are tuples that store the data in the following format:\n",
    "\n",
    "* p-value ($H_0: model_1 = model_2$)\n",
    "* Empirical value (model 1)\n",
    "* CI low (model 1)\n",
    "* CI high (model 1)\n",
    "* Empirical value (model 2)\n",
    "* CI low (model 2)\n",
    "* CI high (model 2)\n",
    "\n",
    "If you launch the code in Binder, decrease the number of bootstrap iterations (`10000` by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ffe5c23-3169-4fe6-9512-4cc91c2bac0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 10000/10000 [00:30<00:00, 324.45it/s]\n"
     ]
    }
   ],
   "source": [
    "testing_result = stambo.compare_models(yte, preds_knn, preds_lr, metrics=(\"ROCAUC\", \"AP\", \"QKappa\", \"BACC\", \"MCC\"), seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8512e7f5-ae48-4615-93f0-e5cee58c9067",
   "metadata": {},
   "source": [
    "If we want to visualize the testing results, they are available in a dict in the format we have described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bae40894-63b3-4836-a574-da7ea51ad9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROCAUC': array([9.99900010e-05, 9.72172447e-01, 9.48864207e-01, 9.91257029e-01,\n",
       "        9.91778223e-01, 9.79622319e-01, 9.99108880e-01]),\n",
       " 'AP': array([9.99900010e-05, 9.69989968e-01, 9.43102214e-01, 9.90846088e-01,\n",
       "        9.94036066e-01, 9.84350198e-01, 9.99497541e-01]),\n",
       " 'QKappa': array([0.6940306 , 0.89362837, 0.83599462, 0.94459118, 0.88445634,\n",
       "        0.82383847, 0.9383927 ]),\n",
       " 'BACC': array([0.82711729, 0.941657  , 0.91037184, 0.96995029, 0.93116897,\n",
       "        0.89705871, 0.96276596]),\n",
       " 'MCC': array([0.56184382, 0.89455841, 0.8380851 , 0.94489108, 0.88892445,\n",
       "        0.83293842, 0.93994144])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b89f2-60bd-4b66-92e3-5add6759236f",
   "metadata": {},
   "source": [
    "Most commonly, we though want to visualize them in a report, paper, or a presentation. For that, we can use a function `to_latex`, and get a cut-and-paste `tabular`. To use it in a LaTeX document, one needs to not forget to import booktabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c2494d9-6801-4028-9423-ea0bdff22f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% \\usepackage{booktabs} <-- do not for get to have this imported. \n",
      "\\begin{tabular}{llllll} \\\\ \n",
      "\\toprule \n",
      "\\textbf{Model} & \\textbf{ROCAUC} & \\textbf{AP} & \\textbf{QKappa} & \\textbf{BACC} & \\textbf{MCC} \\\\ \n",
      "\\midrule \n",
      "kNN & $0.97$ [$0.95$-$0.99$] & $0.97$ [$0.94$-$0.99$] & $0.89$ [$0.84$-$0.94$] & $0.94$ [$0.91$-$0.97$] & $0.89$ [$0.84$-$0.94$] \\\\ \n",
      "LR & $0.99$ [$0.98$-$1.00$] & $0.99$ [$0.98$-$1.00$] & $0.88$ [$0.82$-$0.94$] & $0.93$ [$0.90$-$0.96$] & $0.89$ [$0.83$-$0.94$] \\\\ \n",
      "\\midrule\n",
      "$p$-value & $0.00$ & $0.00$ & $0.69$ & $0.83$ & $0.56$ \\\\ \n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print(stambo.to_latex(testing_result, m1_name=\"kNN\", m2_name=\"LR\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b8744b-8908-4041-87c3-ea62ee8fb91e",
   "metadata": {},
   "source": [
    "## Own metrics\n",
    "\n",
    "Sometimes, having default metrics is not enough, and one may want to have some additional metrics. Let us define an F2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23dc74ff-8055-48f6-a3a0-fcc21e5c884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "from functools import partial\n",
    "from stambo.metrics import Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf5d775-0be2-4c8c-8251-6ede2fda5329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F2Score(Metric):\n",
    "    def __init__(self) -> None:\n",
    "        Metric.__init__(self, partial(fbeta_score, beta=2), int_input=True)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return \"F2Score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afd3e34e-4d18-4045-a49f-121a1b178551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 10000/10000 [00:23<00:00, 421.76it/s]\n"
     ]
    }
   ],
   "source": [
    "testing_result = stambo.compare_models(yte, preds_knn, preds_lr, \n",
    "                                       (\"ROCAUC\", \"AP\", F2Score()),seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10c6e6ab-787f-48b7-98f5-48de84564d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% \\usepackage{booktabs} <-- do not for get to have this imported. \n",
      "\\begin{tabular}{llll} \\\\ \n",
      "\\toprule \n",
      "\\textbf{Model} & \\textbf{ROCAUC} & \\textbf{AP} & \\textbf{F2Score} \\\\ \n",
      "\\midrule \n",
      "kNN & $0.97$ [$0.95$-$0.99$] & $0.97$ [$0.94$-$0.99$] & $0.97$ [$0.95$-$0.99$] \\\\ \n",
      "LR & $0.99$ [$0.98$-$1.00$] & $0.99$ [$0.98$-$1.00$] & $0.98$ [$0.97$-$0.99$] \\\\ \n",
      "\\midrule\n",
      "$p$-value & $0.00$ & $0.00$ & $0.18$ \\\\ \n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print(stambo.to_latex(testing_result, m1_name=\"kNN\", m2_name=\"LR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16f56d4c-114f-4701-80fb-783c1b3d1207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROCAUC': array([9.99900010e-05, 9.72172447e-01, 9.48864207e-01, 9.91257029e-01,\n",
       "        9.91778223e-01, 9.79622319e-01, 9.99108880e-01]),\n",
       " 'AP': array([9.99900010e-05, 9.69989968e-01, 9.43102214e-01, 9.90846088e-01,\n",
       "        9.94036066e-01, 9.84350198e-01, 9.99497541e-01]),\n",
       " 'F2Score': array([0.17658234, 0.97114317, 0.95036943, 0.98758465, 0.98017621,\n",
       "        0.96656217, 0.99041534])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c223df-2833-42a2-9b50-fae76accb6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% \\usepackage{booktabs} <-- do not for get to have this imported. \n",
      "\\begin{tabular}{llll} \\\\ \n",
      "\\toprule \n",
      "\\textbf{Model} & \\textbf{ROCAUC} & \\textbf{AP} & \\textbf{F2Score} \\\\ \n",
      "\\midrule \n",
      "kNN & $0.97$ [$0.95$-$0.99$] & $0.97$ [$0.94$-$0.99$] & $0.97$ [$0.95$-$0.99$] \\\\ \n",
      "LR & $0.99$ [$0.98$-$1.00$] & $0.99$ [$0.98$-$1.00$] & $0.98$ [$0.97$-$0.99$] \\\\ \n",
      "\\midrule\n",
      "$p$-value & $0.00$ & $0.00$ & $0.18$ \\\\ \n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "print(stambo.to_latex(testing_result, m1_name=\"kNN\", m2_name=\"LR\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
